# Configure the WandbLogger by PyTorch Lightning. See
# https://lightning.ai/docs/pytorch/stable/extensions/generated/lightning.pytorch.loggers.WandbLogger.html
# for more information.
# Just the api_key is used by the wandb instance itself and not by WandbLogger.
wandb:
  # (Mandatory) API key to log into wandb. !CAUTION! Do not push this private key to GitHub!
  api_key:
  project:
  online:
  log_model:
  run:
    id:

# See https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-flags for more information.
# Just log_images_every_n_epochs is used by our ImageLogger and not by the PyTorch-Lightning Trainer.
trainer:
  accelerator:
  strategy:
  checkpoint_path:
  devices:
  epochs:
  # How often should the display images (see dataset -> display) be run through the network.
  log_images_every_n_epochs:

dataset:
  batch_size:
  #Checks if all the files in the chosen dataset are in good state
  check_files:
  # Options: 'center', 'random', 'boresight'
  crop_mode:
  # Apply the detector mask. Options: True, False
  input_clamp: 
  # Apply clamping to the input image. Options: True, False
  target_clamp:
  # Apply clamping to the input image. Options: True, False
  sigma_clamp:
  # Apply sigma clamping. Options: True, False
  quantile_clamp:
  # Apply quantile claping. Options: 0.001, 0.01, 0.05, 0.5, 0.95, 0.99, 0.999, 0.9999
  normalize:
  # Normalize the input image. Options: True, False (only set to False to compute statistics of input data)
  constant_img_combs: 
  # Always use the same combinations of img, AGN, and background components per idx. Options: True, False
  det_mask:
  # Set debug to true if debugging. Will make your life easier. Options: True, False
  debug:
  # The parent folder of all datasets
  dir:
  deblend_agn_dir:
  # Use the AGN dataset containing blended sources. Options: <name of the directory containing the dataset>, False
  display:
    # These images are used in our ImageLogger. After log_images_every_n_epochs (see trainer -> log_images_every_n_epochs)
    # we iterate through these images, predict on them and log the inputs (just once), predictions, differences,
    # and true_hr (if available)
    sim_display_name:
    real_display_name:
    comps:
    # Use composed images (img, AGN, background) for the display dataset. Options: True, False
    exposure:
      -
  lr:
    # Amount of agns to be used with one low resolution image. Set to 0 to use no agns.
    agn:
    # Amount of backgrounds to be used with one low resolution image. Set to 0 to use no background.
    background:
    exps:
      -
    max:
    # The dataset lr resolution, all the images will be padded/cropped to this resolution
    # Must be multiples of 32
    res:
  hr:
    # Include agns in the high resolution images
    agn:
    # Include background for high resolution images
    background:
    # Exposure of the high resolution images, in ks. If left empty no high resolution images will be used.
    exp:

    max:
    # This implies the resolution increase
    res:
  # The mode, img or agn. If agn the model samples from agn as if it is an image.
  # Only relevant for datasets with type == sim
  mode:
  name:
  # Options: None and 'linear', 'sqrt', 'asinh', 'log'
  scaling:
  # Options: real, sim
  asinh:
    a: 
    # Parameter in the asinh normalization
  hist_eq:
    tileGridSize:
    # Tile grid size for the histogram equalization normaliation
    clipLimit:
    # Clip limit for the histogram equalization
  divide_dataset:
    # Divide the dataset into input only below or above the clamping threshold or use the entire dataset. Options: 'above', 'below', 'all'
  type:

model:
  # Choose a model by the file name of the .yaml, which contains the model's configuration.
  # The .yaml file has to be located in <project-directory>/res/configs/model/
  name:
  # Decide if the model should use torch.checkpoints (see https://pytorch.org/docs/stable/checkpoint.html)
  # Start with False, if unsure. If False leads to an OOM-Exception, then set to True.
  memory_efficient: